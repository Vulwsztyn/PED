{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# img_class = pickle.load(open(\"gdrive/MyDrive/PED/image_classes.pkl\", \"rb\"))\n",
    "\n",
    "# class_table = {}\n",
    "# # class_table['id'] = []\n",
    "\n",
    "# for i in range(1000):\n",
    "#   class_table[str(i)] = []\n",
    "# for key in img_class.keys():\n",
    "#   # class_table['id'].append(key)\n",
    "#   for i in range(1000):\n",
    "#     class_table[str(i)].append(img_class[key]['all_prob'][0][i])\n",
    "\n",
    "# class_table = pandas.DataFrame(class_table)\n",
    "# pca = PCA(n_components=10)\n",
    "# pca.fit(class_table)\n",
    "# print(pca.components_ )\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GME', 6064),\n",
       " ('Today', 3634),\n",
       " ('Return', 3002),\n",
       " ('Total', 2863),\n",
       " ('AMC', 2777),\n",
       " ('Price', 2647),\n",
       " ('Value', 2636),\n",
       " ('GameStop', 2524),\n",
       " ('Cost', 2408),\n",
       " ('Market', 2314),\n",
       " ('1', 2151),\n",
       " ('A', 2108),\n",
       " ('4', 2107),\n",
       " ('Q', 2041),\n",
       " ('2', 1881),\n",
       " ('Shares', 1853),\n",
       " ('Buy', 1660),\n",
       " ('Volume', 1627),\n",
       " ('stock', 1623),\n",
       " ('shares', 1517),\n",
       " ('2021', 1489),\n",
       " ('Position', 1487),\n",
       " ('7', 1360),\n",
       " ('AM', 1311),\n",
       " ('Avg', 1259),\n",
       " ('Day', 1230),\n",
       " ('Your', 1228),\n",
       " ('Jan', 1209),\n",
       " ('Portfolio', 1207),\n",
       " ('Call', 1178),\n",
       " ('GAMESTOP', 1146),\n",
       " ('0.00', 1136),\n",
       " ('Open', 1111),\n",
       " ('USD', 1074),\n",
       " ('Trade', 1062),\n",
       " ('1M', 1034),\n",
       " ('3M', 1030),\n",
       " ('it', 1001),\n",
       " ('0', 999),\n",
       " ('Order', 973),\n",
       " ('Diversity', 970),\n",
       " ('5', 955),\n",
       " ('We', 941),\n",
       " ('BB', 918),\n",
       " ('price', 913),\n",
       " ('Exp', 904),\n",
       " ('100', 903),\n",
       " ('P/L', 896),\n",
       " ('PM', 894),\n",
       " ('Change', 888),\n",
       " ('View', 887),\n",
       " ('Gain', 884),\n",
       " ('Robinhood', 868),\n",
       " ('P', 858),\n",
       " ('market', 851),\n",
       " ('3', 848),\n",
       " ('The', 846),\n",
       " ('Last', 821),\n",
       " ('Quantity', 799),\n",
       " ('Symbol', 784),\n",
       " ('NOK', 766),\n",
       " ('x', 763),\n",
       " ('10', 762),\n",
       " ('Positions', 760),\n",
       " ('Share', 750),\n",
       " ('1Y', 748),\n",
       " ('Sell', 713),\n",
       " ('Trad', 702),\n",
       " ('NYSE', 700),\n",
       " ('order', 699),\n",
       " ('Close', 671),\n",
       " ('More', 667),\n",
       " ('Average', 647),\n",
       " ('You', 629),\n",
       " ('Buys', 629),\n",
       " ('v', 623),\n",
       " ('L', 620),\n",
       " ('Options', 611),\n",
       " ('Account', 609),\n",
       " ('stocks', 589),\n",
       " ('Limit', 587),\n",
       " ('S', 581),\n",
       " ('ET', 579),\n",
       " ('close', 578),\n",
       " ('BUY', 575),\n",
       " ('Feb', 567),\n",
       " ('US', 563),\n",
       " ('al', 559),\n",
       " ('EST', 558),\n",
       " ('8', 555),\n",
       " ('value', 553),\n",
       " ('This', 552),\n",
       " ('1D', 547),\n",
       " ('CORP', 544),\n",
       " ('LTE', 541),\n",
       " ('Filled', 541),\n",
       " ('Current', 528),\n",
       " ('28', 523),\n",
       " ('I', 520),\n",
       " ('Bid', 502)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv('../../data/reddit_wsb.csv')\n",
    "df[\"body\"] = df[\"body\"].fillna('')\n",
    "df[\"title\"] = df[\"title\"].fillna('')\n",
    "img_clusters = pickle.load(open(\"../../pickle/image_color_clusters.pkl\", \"rb\"))\n",
    "img_means = pickle.load(open(\"../../pickle/image_hsv_means.pkl\", \"rb\"))\n",
    "img_text = pickle.load(open(\"../../pickle/texts.pkl\", \"rb\"))\n",
    "\n",
    "img_most_common = Counter(word_tokenize(' '.join([' '.join(x) for x in img_text.values()])))\n",
    "for key, cnts in list(img_most_common.items()):\n",
    "  if not key in emoji.UNICODE_EMOJI and (key in stopwords.words('english') or not re.match(r'\\w+',key)):\n",
    "    del img_most_common[key]\n",
    "img_most_common = img_most_common.most_common(100)\n",
    "img_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  text_GME  text_Today  text_Return  text_Total  text_AMC  \\\n",
      "0      l0j2uy.jpg         0           2            0           0         0   \n",
      "1      l0jw5j.png         0           0            0           0         0   \n",
      "2      l0k6vs.jpg         0           1            0           0         0   \n",
      "3      l0k7wq.jpg         0           0            0           0         0   \n",
      "4      l0khnn.jpg         0           0            0           0         0   \n",
      "...           ...       ...         ...          ...         ...       ...   \n",
      "10799  lh8j7j.jpg         0           2            2           1         0   \n",
      "10800  lh9q18.jpg         0           2            2           1         0   \n",
      "10801  lh9t7w.png         0           6            6           3         0   \n",
      "10802  lhaeyc.png         0           2            2           1         0   \n",
      "10803  lhcqjk.png         0           0            0           0         0   \n",
      "\n",
      "       text_Price  text_Value  text_GameStop  text_Cost  ...   color_2_b  \\\n",
      "0               0           0              0          0  ...  169.905076   \n",
      "1               0           0              0          0  ...  104.565618   \n",
      "2               0           0              0          0  ...  193.918416   \n",
      "3               0           0              0          0  ...  211.245725   \n",
      "4               0           0              0          0  ...  172.982367   \n",
      "...           ...         ...            ...        ...  ...         ...   \n",
      "10799           0           0              0          1  ...   25.102941   \n",
      "10800           0           1              0          0  ...   62.099646   \n",
      "10801           0           3              0          1  ...  114.920954   \n",
      "10802           1           1              0          2  ...   10.278095   \n",
      "10803           0           0              0          0  ...   88.610657   \n",
      "\n",
      "       color_2_%   color_3_r   color_3_g   color_3_b  color_3_%   color_4_r  \\\n",
      "0       0.024155  105.333594  106.899504  108.278256   0.026524  216.365534   \n",
      "1       0.051073  187.429560  183.045950  185.345102   0.080007   38.111775   \n",
      "2       0.037604  134.454082  125.942041  126.953673   0.033934  206.311814   \n",
      "3       0.176752   86.762005  105.853693   95.578470   0.218006  168.892128   \n",
      "4       0.020422   44.996515   45.572382   46.700916   0.069557  235.718806   \n",
      "...          ...         ...         ...         ...        ...         ...   \n",
      "10799   0.025429  130.313220  128.103051  127.587119   0.010215   45.704237   \n",
      "10800   0.023490    8.221523    8.221523    8.221523   0.011004  172.526210   \n",
      "10801   0.014806   86.048249  186.792058   56.522203   0.016219   34.895012   \n",
      "10802   0.007271  118.701636  134.035611  146.038499   0.007195   44.005566   \n",
      "10803   0.065983  250.367436  250.306920  250.085753   0.025506  131.421736   \n",
      "\n",
      "        color_4_g   color_4_b  color_4_%  \n",
      "0      216.808350  217.196091   0.031184  \n",
      "1       29.584397   94.657164   0.085817  \n",
      "2       41.418143   48.636709   0.016413  \n",
      "3      121.225550   89.883859   0.131330  \n",
      "4      236.314036  236.855388   0.115554  \n",
      "...           ...         ...        ...  \n",
      "10799   66.513559   47.346610   0.008165  \n",
      "10800  182.463038  170.216398   0.010305  \n",
      "10801   40.869679   36.121964   0.026524  \n",
      "10802   35.858534   37.965213   0.014931  \n",
      "10803   33.326179   28.462474   0.050665  \n",
      "\n",
      "[10804 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "pic_data = {}\n",
    "pic_data['id'] = []\n",
    "pic_data['text'] = []\n",
    "pic_data['clusters'] = []\n",
    "pic_data['means'] = []\n",
    "pic_data['score'] = []\n",
    "\n",
    "for key in img_means.keys():\n",
    "  pic_data['id'].append(key)\n",
    "  pic_data['text'].append(\" \".join(img_text[key[:-4]]))\n",
    "  pic_data['clusters'].append(img_clusters[key])\n",
    "  pic_data['means'].append(img_means[key])\n",
    "  pic_data['score'].append(df.loc[df['id'] == key[:-4]]['score'].values[0])\n",
    "\n",
    "pic_data = pandas.DataFrame(pic_data)\n",
    "\n",
    "pic_attributes = {'id': pic_data['id']}\n",
    "for key, cnts in img_most_common: \n",
    "  pic_attributes['text_' + key] =  pic_data['text'].str.lower().str.count(key.lower())\n",
    "\n",
    "pic_attributes['h_sin'] = pic_data['means'].apply(lambda s:  np.sin(2*np.pi*(s[0]/255)))\n",
    "pic_attributes['h_cos'] = pic_data['means'].apply(lambda s:  np.sin(2*np.pi*(s[0]/255)))\n",
    "pic_attributes['s'] = pic_data['means'].apply(lambda s: s[1]/255)\n",
    "pic_attributes['v'] = pic_data['means'].apply(lambda s: s[2]/255)\n",
    "pic_attributes['score'] = pic_data['score']\n",
    "for j in range(5):\n",
    "  for i in range(3):\n",
    "    pic_attributes['color_'+str(j)+'_'+'rgb'[i]] = pic_data['clusters'].apply(lambda s: s['color'][j][i])\n",
    "  pic_attributes['color_'+str(j)+'_%'] = pic_data['clusters'].apply(lambda s: s['percentage'][j])\n",
    "\n",
    "pic_attributes = pandas.DataFrame(pic_attributes)\n",
    "print(pic_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_image_matrix = pic_attributes.corr(method='spearman')\n",
    "\n",
    "correlations = []\n",
    "for i,column in enumerate(corr_image_matrix):\n",
    "  x = corr_image_matrix[column][i+1:]\n",
    "  for row,v in x.items():\n",
    "    correlations.append([v,column,row])\n",
    "correlations.sort(key = lambda x: -abs(x[0]))\n",
    "\n",
    "score_corr = corr_image_matrix['score'][corr_image_matrix['score']<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0606, 'text_A'), (0.0513, 'text_Position'), (0.0356, 'text_Shares'), (0.0324, 'text_Volume'), (0.03, 'text_GameStop'), (0.0296, 'text_Order'), (0.0287, 'text_order'), (0.0271, 'id'), (0.0267, 'text_Total'), (0.0214, 'text_Buy'), (0.0213, 'text_GME'), (0.0205, 'text_4'), (0.0204, 'text_Value'), (0.0194, 'text_Today'), (0.0192, 'text_2021'), (0.0192, 'color_4_g'), (0.0187, 'text_1'), (0.0186, 'text_Price'), (0.0177, 'text_Cost'), (0.0173, 'text_value'), (0.0172, 'text_stock'), (0.0166, 'text_Q'), (0.0165, 'text_2'), (0.0162, 'text_AMC'), (0.0157, 'text_shares'), (0.0155, 'text_Market'), (0.015, 'text_Open'), (0.0148, 'text_Return'), (0.0141, 'text_Symbol'), (0.0137, 'text_Bid'), (0.0135, 'color_3_b'), (0.0125, 'text_Trad'), (0.0116, 'text_This'), (0.0107, 'text_Limit'), (0.0107, 'text_1M'), (0.0104, 'text_7'), (0.0097, 'text_Avg'), (0.0091, 'color_1_g'), (0.0089, 'text_Current'), (0.0085, 'text_v'), (0.0085, 's'), (0.0075, 'color_1_%'), (0.0073, 'color_0_b'), (0.0066, 'text_it'), (0.0065, 'text_ET'), (0.006, 'text_GAMESTOP'), (0.006, 'text_0'), (0.0056, 'text_3M'), (0.0054, 'text_USD'), (0.005, 'text_More'), (0.005, 'color_0_%'), (0.0047, 'text_Quantity'), (0.0047, 'text_Diversity'), (0.0046, 'color_3_r'), (0.0044, 'text_Gain'), (0.004, 'text_al'), (0.004, 'text_Share'), (0.0039, 'text_I'), (0.0036, 'text_Change'), (0.0036, 'text_AM'), (0.0036, 'text_28'), (0.0036, 'h_sin'), (0.0034, 'text_5'), (0.0034, 'color_3_%'), (0.0034, 'color_1_b'), (0.0033, 'text_We'), (0.0032, 'text_1D'), (0.0031, 'text_The'), (0.003, 'color_0_r'), (0.0029, 'score'), (0.0026, 'text_NYSE'), (0.0025, 'color_1_r'), (0.0024, 'text_P'), (0.0023, 'text_PM'), (0.0023, 'text_Close'), (0.0022, 'text_View'), (0.0022, 'text_100'), (0.0021, 'text_Robinhood'), (0.0021, 'color_4_r'), (0.002, 'color_2_r'), (0.0019, 'text_x'), (0.0019, 'text_Sell'), (0.0019, 'text_Positions'), (0.0019, 'h_cos'), (0.0018, 'text_market'), (0.0018, 'text_L'), (0.0018, 'text_Day'), (0.0016, 'text_Filled'), (0.0013, 'text_P/L'), (0.0013, 'text_1Y'), (0.0013, 'color_0_g'), (0.0012, 'text_LTE'), (0.0011, 'text_You'), (0.0011, 'text_CORP'), (0.0011, 'text_BUY'), (0.0011, 'text_Average'), (0.0011, 'color_3_g'), (0.001, 'text_Your'), (0.001, 'text_NOK'), (0.001, 'text_BB'), (0.001, 'text_Account'), (0.001, 'text_0.00'), (0.0009, 'text_Options'), (0.0009, 'text_Feb'), (0.0009, 'text_Buys'), (0.0008, 'text_close'), (0.0008, 'color_2_%'), (0.0007, 'text_US'), (0.0007, 'text_3'), (0.0007, 'color_2_b'), (0.0006, 'text_Trade'), (0.0006, 'text_Call'), (0.0004, 'text_price'), (0.0004, 'text_Portfolio'), (0.0004, 'color_2_g'), (0.0003, 'text_Jan'), (0.0003, 'text_Exp'), (0.0003, 'text_8'), (0.0002, 'v'), (0.0002, 'text_stocks'), (0.0002, 'text_S'), (0.0001, 'text_Last'), (0.0001, 'text_EST'), (0.0001, 'text_10')]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(pic_attributes[pic_attributes.columns.difference(['id', 'score'])], pic_attributes['score'])\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), pic_attributes.head()), \n",
    "             reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
